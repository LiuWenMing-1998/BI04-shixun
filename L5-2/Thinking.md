Thinking1	在CTR点击率预估中，使用GBDT+LR的原理是什么？

GDBT是将所有树的结果累加起来作为最终的结果，每一棵树学习的是前一颗树的残差。也就是说该算法在每一轮迭代中，先计算出当前模型在所有样本上的负梯度，然后以该值为目标训练一个新的弱分类器进行拟合并计算出该弱分类器的权重，最终实现对模型的更新。当GBDT训练好做预测的时候，输出的并不是最终的二分类概率值，而是要把模型中的每棵树计算得到的预测概率值所属的叶子结点位置记为1从而构造新出的训练数据。最后对新训练出的训练数据来进行LR预测。

Thinking2	Wide & Deep的模型结构是怎样的，为什么能通过具备记忆和泛化能力（memorization and generalization）		

Wide&Deep结合线性模型的记忆能力和DNN模型的泛化能力，在训练过程中同时优化两个模型的参数。Wide主要用于低阶项，Deep主要用于高阶项。

Thinking3	在CTR预估中，使用FM与DNN结合的方式，有哪些结合的方式，代表模型有哪些？	

有两种结合的方式：DeepFM,并行结构，FM和DNN分开计算；NFM，串行架构，将FM的输出作为DNN的输入。

Thinking4	GBDT和随机森林都是基于树的算法，它们有什么区别？

GBDT是一种迭代的决策树算法，该算法由多棵决策树组成，所有树的结论累加起来做最终结果。GSDT的树是回归树，不是分类树，调整使用sigmod也可以用于分类。而随机森林是用随机的方式建立一个森林，森林里面有很多的决策树组成，随机森林的每一棵决策树之间是没有关联的。在得到森林之后，当有一个新的输入样本进入的时候，就让森林中的每一棵决策树分别进行一下判断，看看这个样本应该属于哪一类（对于分类算法），然后看看哪一类被选择最多，就预测这个样本为那一类。随机森林既可以分类预测也可以做回归预测。

Thinking5	item流行度在推荐系统中有怎样的应用

商品的流行程度，也是商品的热度，最常见的是将系统中热度的商品推荐给用户。它可以解决系统的冷启动问题，根据流行度来推荐商品的算法，也就是什么内容吸引用户，就给用户推荐什么内容。
